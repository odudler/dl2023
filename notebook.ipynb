{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reload_ext dotenv\n",
    "#%dotenv\n",
    "\n",
    "# ML libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Local imports\n",
    "from env import Env\n",
    "from agents.random_agent import RandomAgent\n",
    "from agents.minimax_agent import MinimaxAgent\n",
    "from agents.minimax_agent_old import OldMinimaxAgent\n",
    "from agents.deep_q_agent import DeepQAgent\n",
    "# from agents.deep_q_agent_modified import DeepQAgent\n",
    "from agents.cql_agent import CQLAgent\n",
    "import utils\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# INITIALIZATION #\n",
    "##################\n",
    "\n",
    "# Fix random seed\n",
    "utils.seed_everything(42, deterministic=False)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define player and opponent IDs\n",
    "AGENT = 1\n",
    "OPPONENT = 2\n",
    "\n",
    "# Define game environment, this should be passed to the agents and the trainer\n",
    "env = Env()\n",
    "\n",
    "# Define agent and opponent\n",
    "state_shape = env.get_state(state_type='boolean', player=AGENT).shape\n",
    "agent = CQLAgent(env=env, state_size=state_shape, action_size=7, network_type='CNN')\n",
    "agent.load_model('./saved_models/CQLAgent_CNN_25783.pt')\n",
    "# agent = CQLAgent(env=env, state_size=42, action_size=7, network_type='DDQN')\n",
    "# agent = DeepQAgent(env=env, epsilon_max=1, epsilon_min=0.1, epsilon_decay=0.9999, device=device)\n",
    "opponent = MinimaxAgent(env=env, depth=3, epsilon=0.5, player=OPPONENT)\n",
    "replacement_agent = MinimaxAgent(env=env, depth=3, epsilon=0.5, player=OPPONENT)\n",
    "\n",
    "# Define options for training\n",
    "options = {\n",
    "           'UPDATE_OPPONENT': True,                         # Whether to enable self-play or not\n",
    "           'OPPONENT_UPDATE_FREQUENCY': 500,                # After how many episodes the opponent will be replaced by the current agent\n",
    "           'BOOTSTRAP_EPISODES': 0000,                      # During this time, the agent will not be replaced by itself\n",
    "           'DECAY_RANDOMNESS_OPPONENT': False,              # Decay randomness of the opponent. Use only if the opponent acts with some randomness\n",
    "           'DECAY_RANDOMNESS_FREQUENCY': 1000,              # Frequency of randomness decay\n",
    "           'REPLACE_FOR_EVALUATION': True,                  # Whether to replace the training model at the end with another evaluation model\n",
    "           'REPLACE_FOR_EVALUATION_BY': replacement_agent,  # Evalutation model to replace training model by\n",
    "           'AUTOSAVE': True,                                # Whether to save the model at certain intervals\n",
    "           'AUTOSAVE_TYPE': 'NUM_EPISODES',                 # One of [\"NUM_OPTIMIZATIONS\", \"NUM_EPISODES\"]\n",
    "           'AUTOSAVE_PERIOD': 1000,                         # After how many _ to save the model\n",
    "           }\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(env=env, agent=agent, opponent=opponent, agent_id=AGENT, opponent_id=OPPONENT, num_episodes={'TRAIN': 5000, 'EVAL': 100}, device=device, verbose=True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Running episode 5000 of 5000. Current win ratio of AGENT is 42.94%.\n",
      "TRAIN: Average turns per episode 24.4138\n",
      "TRAIN: Average invalid moves per episode 0.0\n",
      "\n",
      "\n",
      "EVAL: Running episode 100 of 100. Current win ratio of AGENT is 35.00%.\n",
      "EVAL: Average turns per episode 10.69\n",
      "EVAL: Average invalid moves per episode 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# TRAINING #\n",
    "############\n",
    "\n",
    "# Train agent\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: Ran episode 100 of 100. Ratios are [WINS: 33.00% | LOSSES: 67.00% | TIES: 0]                                                \n",
      "EVAL: Average turns per episode 10.58\n",
      "EVAL: Average invalid moves per episode 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# QUICK EVALUATION #\n",
    "####################\n",
    "\n",
    "# Fix random seed\n",
    "utils.seed_everything(42, deterministic=False)\n",
    "\n",
    "# Define player and opponent IDs\n",
    "AGENT = 1\n",
    "OPPONENT = 2\n",
    "\n",
    "# Fix random seed\n",
    "utils.seed_everything(42, deterministic=False)\n",
    "\n",
    "eval_env = Env()\n",
    "# Load agent from save and set to eval mode\n",
    "state_shape = env.get_state(state_type='boolean', player=AGENT).shape\n",
    "agent = CQLAgent(env=eval_env, state_size=state_shape, action_size=7, network_type='CNN')\n",
    "agent.load_model('./saved_models/CQLAgent_CNN_60936.pt')\n",
    "\n",
    "# Define opponent\n",
    "minmax_opponent = MinimaxAgent(env=eval_env, depth=3, epsilon=0.5, player=OPPONENT)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(env=eval_env, agent=agent, opponent=opponent, agent_id=AGENT, opponent_id=OPPONENT, num_episodes={'TRAIN': 10000, 'EVAL': 100}, device=device, verbose=True, options=options)\n",
    "# Run evaluation\n",
    "trainer.eval(agent=agent, opponent=minmax_opponent, episodes=100, agent_start=None, print_last_n_games=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

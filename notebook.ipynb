{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "# ML libraries\n",
    "import torch\n",
    "\n",
    "# Local imports\n",
    "from env import Env\n",
    "from agents.random_agent import RandomAgent\n",
    "from agents.minimax_agent import MinimaxAgent\n",
    "from agents.minimax_agent_old import OldMinimaxAgent\n",
    "from agents.deep_q_agent import DeepQAgent\n",
    "from agents.cql_agent import CQLAgent\n",
    "import utils\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# INITIALIZATION #\n",
    "##################\n",
    "\n",
    "# Fix random seed\n",
    "utils.seed_everything(42, deterministic=False)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define player and opponent IDs\n",
    "AGENT = 1\n",
    "OPPONENT = 2\n",
    "\n",
    "# Define agent and opponent\n",
    "agent = CQLAgent(epsilon_max=1, epsilon_min=0.1, epsilon_decay=0.9999, device=device)\n",
    "opponent = MinimaxAgent(depth=3, epsilon=0.5, player=OPPONENT)\n",
    "replacement_agent = MinimaxAgent(depth=3, epsilon=0.5, player=OPPONENT)\n",
    "\n",
    "# Define options for training\n",
    "options = {\n",
    "           'UPDATE_OPPONENT': True,                         # Whether to enable self-play or not\n",
    "           'OPPONENT_UPDATE_FREQUENCY': 100,                # After how many episodes the opponent will be replaced by the current agent\n",
    "           'BOOTSTRAP_EPISODES': 7500,                      # During this time, the agent will not be replaced by itself\n",
    "           'DECAY_RANDOMNESS_OPPONENT': True,               # Decay randomness of the opponent. Use only if the opponent acts with some randomness\n",
    "           'DECAY_RANDOMNESS_FREQUENCY': 1000,              # Frequency of randomness decay\n",
    "           'REPLACE_FOR_EVALUATION': True,                  # Whether to replace the training model at the end with another evaluation model\n",
    "           'REPLACE_FOR_EVALUATION_BY': replacement_agent,  # Evalutation model to replace training model by\n",
    "           'AUTOSAVE': True,                                # Whether to save the model at certain intervals\n",
    "           'AUTOSAVE_TYPE': 'NUM_EPISODES',                 # One of [\"NUM_OPTIMIZATIONS\", \"NUM_EPISODES\"]\n",
    "           'AUTOSAVE_PERIOD': 1000,                         # After how many _ to save the model\n",
    "           }\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(env=Env(), agent=agent, opponent=opponent, num_episodes={'TRAIN': 10000, 'EVAL': 100}, agent_id=AGENT, opponent_id=OPPONENT, device=device, verbose=True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "type(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Running episode 34 of 10000. Current win ratio of AGENT is 5.88%."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m############\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# TRAINING #\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m############\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train agent\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dl/dl-proj/dl2023/trainer.py:143\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m agent_start \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m])\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Run one episode of the game and update running variables\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m finished, turns, invalid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mturns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvalid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Update scores with winner\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m finished \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/dl/dl-proj/dl2023/trainer.py:214\u001b[0m, in \u001b[0;36mTrainer.play_episode\u001b[0;34m(self, mode, agent, opponent, agent_start, turns, invalid, print_game)\u001b[0m\n\u001b[1;32m    212\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mget_state() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(opponent) \u001b[38;5;129;01min\u001b[39;00m [RandomAgent, MinimaxAgent, DeepQAgent, CQLAgent] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Predict best next action based on this state\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mopponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Execute action\u001b[39;00m\n\u001b[1;32m    216\u001b[0m valid, _, finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mOPPONENT)\n",
      "File \u001b[0;32m~/dl/dl-proj/dl2023/agents/minimax_agent.py:33\u001b[0m, in \u001b[0;36mMinimaxAgent.act\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mact\u001b[39m(\u001b[38;5;28mself\u001b[39m, env: Env):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Choose best predicted action\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon:\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_predicted_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrandom_valid_action()\n",
      "File \u001b[0;32m~/dl/dl-proj/dl2023/agents/minimax_agent.py:84\u001b[0m, in \u001b[0;36mMinimaxAgent.best_predicted_action\u001b[0;34m(self, board, depth, player)\u001b[0m\n\u001b[1;32m     81\u001b[0m tempBoard\u001b[38;5;241m.\u001b[39mplay(player, move)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Call min on that new board\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m boardScore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimizeBeta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtempBoard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopponent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m boardScore \u001b[38;5;241m>\u001b[39m bestScore:\n\u001b[1;32m     86\u001b[0m     bestScore \u001b[38;5;241m=\u001b[39m boardScore\n",
      "File \u001b[0;32m~/dl/dl-proj/dl2023/agents/minimax_agent.py:109\u001b[0m, in \u001b[0;36mMinimaxAgent.minimizeBeta\u001b[0;34m(self, board, depth, a, b, player, opponent)\u001b[0m\n\u001b[1;32m    107\u001b[0m     tempBoard \u001b[38;5;241m=\u001b[39m deepcopy(board)\n\u001b[1;32m    108\u001b[0m     tempBoard\u001b[38;5;241m.\u001b[39mplay(opponent, move)\n\u001b[0;32m--> 109\u001b[0m     boardScore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximizeAlpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtempBoard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopponent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m boardScore \u001b[38;5;241m<\u001b[39m beta:\n\u001b[1;32m    111\u001b[0m     beta \u001b[38;5;241m=\u001b[39m boardScore\n",
      "File \u001b[0;32m~/dl/dl-proj/dl2023/agents/minimax_agent.py:131\u001b[0m, in \u001b[0;36mMinimaxAgent.maximizeAlpha\u001b[0;34m(self, board, depth, a, b, player, opponent)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alpha \u001b[38;5;241m<\u001b[39m b:\n\u001b[1;32m    130\u001b[0m     tempBoard \u001b[38;5;241m=\u001b[39m deepcopy(board)\n\u001b[0;32m--> 131\u001b[0m     \u001b[43mtempBoard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmove\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     boardScore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminimizeBeta(tempBoard, depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, alpha, b, player, opponent)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m boardScore \u001b[38;5;241m>\u001b[39m alpha:\n",
      "File \u001b[0;32m~/dl/dl-proj/dl2023/board.py:108\u001b[0m, in \u001b[0;36mConnectFourField.play\u001b[0;34m(self, player, action)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03mreturns tuple (successful, finished)\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03msuccessful: 0 if move was successful, -1 if the given action is illegal (column full)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mfinished: -1: not finished, 0: tie, x: player x won\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_col_free_entry(action)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield[row][action] \u001b[38;5;241m=\u001b[39m player\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############\n",
    "# TRAINING #\n",
    "############\n",
    "\n",
    "# Train agent\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: Running episode 96 of 100. Ratios are [WINS: 21.88% | LOSSES: 77.08% | TIES: 1.04%]]\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|0|0|0|0|0|0|\n",
      "===============\n",
      "AGENT action was 0\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|2|0|0|0|0|0|\n",
      "===============\n",
      "OPPONENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|2|0|0|0|0|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|2|2|0|0|0|0|\n",
      "===============\n",
      "OPPONENT action was 2\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|2|2|0|0|0|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|2|2|0|0|2|0|\n",
      "===============\n",
      "OPPONENT action was 5\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|2|2|0|0|2|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|0|0|0|0|0|\n",
      "|1|2|2|0|0|2|0|\n",
      "===============\n",
      "OPPONENT action was 0\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|2|2|0|0|2|0|\n",
      "===============\n",
      "AGENT action was 2\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|2|2|0|0|2|0|\n",
      "===============\n",
      "OPPONENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|2|2|0|0|2|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|2|2|2|0|2|0|\n",
      "===============\n",
      "OPPONENT action was 3\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|2|2|2|0|2|0|\n",
      "===============\n",
      "AGENT action was invalid\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|2|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|2|2|2|0|2|0|\n",
      "===============\n",
      "OPPONENT action was 2\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|2|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|2|2|2|0|2|0|\n",
      "===============\n",
      "AGENT action was invalid\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|2|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|2|2|2|0|2|0|\n",
      "===============\n",
      "OPPONENT action was 0\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|2|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|2|2|2|0|2|0|\n",
      "===============\n",
      "AGENT action was invalid\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|2|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|2|2|2|2|2|0|\n",
      "===============\n",
      "OPPONENT action was 4\n",
      "EVAL: Running episode 97 of 100. Ratios are [WINS: 21.65% | LOSSES: 77.32% | TIES: 1.03%]\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|0|0|0|0|0|0|\n",
      "===============\n",
      "AGENT action was 0\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|0|0|0|0|0|2|\n",
      "===============\n",
      "OPPONENT action was 6\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|1|0|0|0|0|2|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|1|0|0|2|0|2|\n",
      "===============\n",
      "OPPONENT action was 4\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|1|0|0|2|0|2|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|2|1|0|0|0|0|0|\n",
      "|1|1|0|0|2|0|2|\n",
      "===============\n",
      "OPPONENT action was 0\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|0|0|0|0|0|\n",
      "|1|1|0|0|2|0|2|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|0|0|0|0|0|\n",
      "|1|1|0|0|2|0|2|\n",
      "===============\n",
      "OPPONENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|0|0|0|0|0|\n",
      "|1|1|1|0|2|0|2|\n",
      "===============\n",
      "AGENT action was 2\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|0|0|0|0|0|\n",
      "|1|1|1|0|2|2|2|\n",
      "===============\n",
      "OPPONENT action was 5\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|1|0|0|0|0|\n",
      "|1|1|1|0|2|2|2|\n",
      "===============\n",
      "AGENT action was 2\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|2|1|1|0|0|2|0|\n",
      "|1|1|1|0|2|2|2|\n",
      "===============\n",
      "OPPONENT action was 5\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|1|0|0|0|0|\n",
      "|2|1|1|0|0|2|0|\n",
      "|1|1|1|0|2|2|2|\n",
      "===============\n",
      "AGENT action was 2\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|1|0|0|0|0|\n",
      "|2|1|1|0|0|2|2|\n",
      "|1|1|1|0|2|2|2|\n",
      "===============\n",
      "OPPONENT action was 6\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|2|1|0|0|0|0|\n",
      "|0|1|1|0|0|0|0|\n",
      "|2|1|1|0|0|2|2|\n",
      "|1|1|1|0|2|2|2|\n",
      "===============\n",
      "AGENT action was 2\n",
      "EVAL: Running episode 98 of 100. Ratios are [WINS: 22.45% | LOSSES: 76.53% | TIES: 1.02%]\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|2|0|0|0|\n",
      "===============\n",
      "OPPONENT action was 3\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|2|0|0|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|2|2|0|0|\n",
      "===============\n",
      "OPPONENT action was 4\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|2|2|0|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|2|2|0|0|\n",
      "===============\n",
      "OPPONENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|2|2|0|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|2|2|2|0|\n",
      "===============\n",
      "OPPONENT action was 5\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|1|2|2|2|0|\n",
      "===============\n",
      "AGENT action was 2\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|2|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|1|2|2|2|2|\n",
      "===============\n",
      "OPPONENT action was 6\n",
      "EVAL: Running episode 99 of 100. Ratios are [WINS: 22.22% | LOSSES: 76.77% | TIES: 1.01%]\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|0|0|0|0|0|0|\n",
      "===============\n",
      "AGENT action was 0\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|0|0|2|0|0|0|\n",
      "===============\n",
      "OPPONENT action was 3\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|1|0|2|0|0|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|1|0|2|0|0|2|\n",
      "===============\n",
      "OPPONENT action was 6\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|1|0|2|0|0|2|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|1|0|2|2|0|2|\n",
      "===============\n",
      "OPPONENT action was 4\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|1|0|2|2|0|2|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|2|\n",
      "|1|1|0|2|2|0|2|\n",
      "===============\n",
      "OPPONENT action was 6\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|2|\n",
      "|1|1|1|2|2|0|2|\n",
      "===============\n",
      "AGENT action was 2\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|2|\n",
      "|1|1|1|2|2|2|2|\n",
      "===============\n",
      "OPPONENT action was 5\n",
      "EVAL: Running episode 100 of 100. Ratios are [WINS: 22.00% | LOSSES: 77.00% | TIES: 1.00%]                             \n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|0|0|0|0|0|0|\n",
      "===============\n",
      "AGENT action was 0\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|0|2|0|0|0|0|\n",
      "===============\n",
      "OPPONENT action was 2\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|1|2|0|0|0|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|1|1|2|2|0|0|0|\n",
      "===============\n",
      "OPPONENT action was 3\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|1|2|2|0|0|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|1|2|2|2|0|0|\n",
      "===============\n",
      "OPPONENT action was 4\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|1|2|2|2|0|0|\n",
      "===============\n",
      "AGENT action was 1\n",
      "\n",
      "\n",
      "_______________\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|0|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|0|1|0|0|0|0|0|\n",
      "|1|1|2|2|2|2|0|\n",
      "===============\n",
      "OPPONENT action was 5\n",
      "\n",
      "EVAL: Average turns per episode 10.8\n",
      "EVAL: Average invalid moves per episode 0.45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# QUICK EVALUATION #\n",
    "####################\n",
    "\n",
    "# Fix random seed\n",
    "utils.seed_everything(42, deterministic=False)\n",
    "\n",
    "# Load agent from save and set to eval mode\n",
    "new_agent = CQLAgent()\n",
    "new_agent.load_model('./saved_models/CQLAgent_46515_no_replacement')\n",
    "new_agent.eval_mode()\n",
    "\n",
    "# Define opponent\n",
    "new_opponent = MinimaxAgent(depth=3, epsilon=0.5, player=OPPONENT)\n",
    "\n",
    "# Run evaluation\n",
    "trainer.eval(trainer.agent, new_opponent, agent_start=None, print_last_n_games=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
